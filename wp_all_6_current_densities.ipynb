{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Davide Aloi - PhD student - University of Birmingham\n",
    "# Description: the script calculates current density maps starting from electric magnitude\n",
    "# maps (Emag) generated using ROAST, for each of the 3 datasets included in the analysis\n",
    "# (namely wp1a, wp1b and wp2a).\n",
    "# Results are saved in 4d nifti files (1 volume per subject). For convenience, electric \n",
    "# field maps and masks are also saved in 4d nifti files.\n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "from nilearn.image import new_img_like\n",
    "from scipy import ndimage\n",
    "import scipy.io\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "# Function to calculate current density\n",
    "from custom_functions.maps_functions import current_density_efield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters and variables: \n",
    "main_folder = 'C:\\\\Users\\\\davide\\\\Documents\\\\GitHub\\\\wp1_2_roast\\\\' \n",
    "output_folder = 'D:\\\\roast-chapter3\\\\wp_all_results\\\\' # where to save e-field maps, current density maps and brain masks\n",
    "data_folder = 'D:\\\\roast-chapter3\\\\'\n",
    "# Tissue conductivities:\n",
    "conductivities = [0.126, 0.276, 1.65] #WM, GM and CSF\n",
    "fwhm_k = 4 # FWHM kernel used to smooth current density maps\n",
    "\n",
    "# Datasets names and subjects lists\n",
    "db_names = ['wp2a', 'wp1b']\n",
    "db_subjects = [['01','02','03','04','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','22','23','24'], #Wp2a\n",
    "               ['01','02','03','04','05','06','07','08','09','10','11','12','13','15','16','17','18','19','21','22','23'], #Wp1b\n",
    "               #['03','04','05','07','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26'] # Wp1a (copying data atm)\n",
    "               ]\n",
    "\n",
    "## Loading AAL3 atlas and extracting M1 / Thalamus ROIs (regions of interest)\n",
    "# AAL3 atlas paper: https://www.oxcns.org/papers/607%20Rolls%20Huang%20Lin%20Feng%20Joliot%202020%20AAL3.pdf \n",
    "AAl3_path = os.path.join(main_folder, 'rois', 'AAL3v1_1mm.nii')\n",
    "AAL3_atlas = image.load_img(AAl3_path)\n",
    "\n",
    "## Creating M1 and Th masks from the AAL3 atlas. Loading MNI template\n",
    "# AAL3 index for left M1 = 1\n",
    "m1 = image.math_img(\"np.where(img == 1, 1, 0)\", img = AAL3_atlas) \n",
    "# AAL3 index for TH = 121 - 149 (odd values only (left thalamus)) --> I'm not convinced about this one, ask davinia\n",
    "th = image.math_img(\"np.where(np.isin(img, np.arange(121, 150, 2)), 1, 0)\", img = AAL3_atlas) \n",
    "\n",
    "# MNI template for plotting and masking purposes\n",
    "bg_img_map = image.load_img(os.path.join(main_folder, 'rois', 'MNI152_T1_1mm_Brain.nii'))\n",
    "bg_img_map_smoothed = image.smooth_img(bg_img_map, fwhm=4) # MNI template smoothed (plotting purposes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db_id, db in enumerate(db_names): #Iterate all datasets\n",
    "    db_path = os.path.join(data_folder, db)\n",
    "\n",
    "    for i, subject in enumerate(db_subjects[db_id]): #Iterate all subjects\n",
    "        path = db_path + '\\sub-' + subject # Subject folder\n",
    "\n",
    "        # Loading normalised Electric field magnitude map (emag) (unit: V/m) (e.g. wsub-*_emag.nii)\n",
    "        # NB: The map was resampled and normalised with wp*_roast_3_post_roast_preprocessing.m\n",
    "        emag_map = image.load_img(glob.glob(path + '\\w*_emag.nii'))\n",
    "\n",
    "        # The above scan (and all the other ones that will be loaded) has 4 dimensions, with the 4th one referring to\n",
    "        # the number of volumes. However, these are 3d scans, I therefore drop the 4th dimension (i.e. from (157, 189, 156, 1)) to\n",
    "        # (157, 189, 156). This is handy when performing mathematical operations on the scans.\n",
    "        scan_shape = emag_map.get_fdata().shape[0:3] # Shape of the scan (should be = (157, 189, 156))    \n",
    "        emag_data = emag_map.get_fdata().reshape(scan_shape) # Data with 4th dimention in the array dropped\n",
    "        emag_map = new_img_like(emag_map, emag_data) #  Restoring the data into a nibabel object\n",
    "\n",
    "        # Resampling MNI anatomical file and ROIs to emag map (so that they have the same shape).\n",
    "        # This is done only once as the shape is the same for every participant's map.\n",
    "        if not 'mni_resampled' in locals():\n",
    "            mni_resampled = image.resample_to_img(bg_img_map, emag_map, interpolation = 'nearest')\n",
    "        if not 'm1_resampled' in locals():\n",
    "            m1_resampled = image.resample_to_img(m1, emag_map, interpolation = 'nearest')\n",
    "            th_resampled = image.resample_to_img(th, emag_map, interpolation = 'nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bb2e88c02631c9acdb2cca42b47db8d956c77e5d847ec74ace7cfa2c4442818"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('neuroimg': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
